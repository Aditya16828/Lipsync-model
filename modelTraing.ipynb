{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import librosa\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "from pathlib import PurePath\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./dataset/test-clean.csv')\n",
    "new_df = df[['subset', 'reader_id', 'chapter_id']].to_numpy()\n",
    "\n",
    "filePaths = []\n",
    "\n",
    "for el in new_df:\n",
    "    subset = el[0].strip()\n",
    "    readerid = el[1]\n",
    "    chapterid = el[2]\n",
    "    folderPath = f'./dataset/{subset}/LibriSpeech/{subset}/{readerid}/{chapterid}/'\n",
    "    textFile = f'{readerid}-{chapterid}.trans.txt'\n",
    "    # print(folderPath + textFile)\n",
    "    with open(folderPath + textFile, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            filename = line.split(' ')[0]\n",
    "            filePaths.append(folderPath + filename + '.flac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2620"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = len(filePaths)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePaths_wav = [el.replace('.flac', '.wav') for el in filePaths]\n",
    "filePaths_json = [el.replace('.flac', '.json') for el in filePaths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adity\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\feature\\spectral.py:2143: UserWarning: Empty filters detected in mel frequency basis. Some channels will produce empty responses. Try increasing your sampling rate (and fmax) or reducing n_mels.\n",
      "  mel_basis = filters.mel(sr=sr, n_fft=n_fft, **kwargs)\n",
      "C:\\Users\\adity\\AppData\\Roaming\\Python\\Python311\\site-packages\\librosa\\core\\spectrum.py:257: UserWarning: n_fft=256 is too large for input signal of length=221\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "131 (5.0 %) files processed\n",
      "262 (10.0 %) files processed\n",
      "393 (15.0 %) files processed\n",
      "524 (20.0 %) files processed\n",
      "655 (25.0 %) files processed\n",
      "786 (30.0 %) files processed\n",
      "917 (35.0 %) files processed\n",
      "1048 (40.0 %) files processed\n",
      "1179 (45.0 %) files processed\n",
      "1310 (50.0 %) files processed\n",
      "1441 (55.0 %) files processed\n",
      "1572 (60.0 %) files processed\n",
      "1703 (65.0 %) files processed\n",
      "1834 (70.0 %) files processed\n",
      "1965 (75.0 %) files processed\n",
      "2096 (80.0 %) files processed\n",
      "2227 (85.0 %) files processed\n",
      "2358 (90.0 %) files processed\n",
      "2489 (95.0 %) files processed\n",
      "2620 (100.0 %) files processed\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "\n",
    "for idx in range(0, len(filePaths_wav)):\n",
    "    jsonFile = open(filePaths_json[idx], 'r')\n",
    "    jsonData = json.load(jsonFile)\n",
    "    # audio = AudioSegment.from_wav(filePaths_wav[idx])\n",
    "    timestamps = jsonData['mouthCues']\n",
    "    for i in range(0, len(timestamps)):\n",
    "        # start = timestamps[i]['start']*1000\n",
    "        # end = timestamps[i]['end']*1000\n",
    "        # newAudio = audio[start:end]\n",
    "        data, samplingRate = librosa.load(filePaths_wav[idx].replace('.wav', '') + '/' + str(i) + '.wav')\n",
    "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=samplingRate, n_mfcc=40, n_fft=256, hop_length=64).T, axis=0)\n",
    "        # mfccs = librosa.feature.mfcc(y=data, sr=samplingRate, n_mfcc=40)\n",
    "        features.append([mfccs, timestamps[i]['value']])\n",
    "    \n",
    "    if(100 * (idx+1)/len(filePaths_wav) % 5 == 0):\n",
    "        print(f\"{idx+1} ({100 * (idx+1)/len(filePaths_wav)} %) files processed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>mouthCue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-805.66187, 47.363415, -81.06073, 50.632145, ...</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-713.58356, 29.172215, -66.59457, 73.78922, -...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-656.05664, 27.86562, -81.64793, 103.50443, -...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-539.1748, 84.53672, -111.58639, 38.384792, -...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-587.18823, 25.168352, -52.31743, 35.61607, -...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            features mouthCue\n",
       "0  [-805.66187, 47.363415, -81.06073, 50.632145, ...        X\n",
       "1  [-713.58356, 29.172215, -66.59457, 73.78922, -...        B\n",
       "2  [-656.05664, 27.86562, -81.64793, 103.50443, -...        A\n",
       "3  [-539.1748, 84.53672, -111.58639, 38.384792, -...        C\n",
       "4  [-587.18823, 25.168352, -52.31743, 35.61607, -...        B"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.DataFrame(features, columns=['features', 'mouthCue'])\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mouthCue\n",
       "B    38132\n",
       "C    26101\n",
       "A    11711\n",
       "E     9594\n",
       "F     8475\n",
       "X     7862\n",
       "G     5604\n",
       "D     3332\n",
       "H     2784\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['mouthCue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy='auto')\n",
    "X_sm, y_sm = smote.fit_resample(dataset['features'].tolist(), dataset['mouthCue'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sm = np.array(y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm = np.array(X_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343188, 40)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    38132\n",
       "B    38132\n",
       "C    38132\n",
       "D    38132\n",
       "E    38132\n",
       "F    38132\n",
       "G    38132\n",
       "H    38132\n",
       "X    38132\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_sm).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.features[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = np.array(dataset.features.tolist())\n",
    "# # X = dataset.features.to_numpy()\n",
    "# y = np.array(dataset.mouthCue.tolist())\n",
    "\n",
    "X = X_sm\n",
    "y = y_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343188,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'X']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mouthCues = pd.get_dummies(y).keys().to_list()\n",
    "mouthCues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new = np.array(pd.get_dummies(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343188, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(343188, 40)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_new, test_size=0.3, random_state = 42, stratify=y_new)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state = 42, stratify=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51479, 40), (240231, 40), (51478, 40))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((51479, 9), (240231, 9), (51478, 9))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_train.shape[1]\n",
    "# inputShape = (X_train.shape[1], X_train.shape[2], X_train.shape[3])\n",
    "inputShape = (X_train.shape[1],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1], 1))\n",
    "# X_val = X_val.reshape((X_val.shape[0], 1, X_val.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 38, 32)            128       \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1  (None, 19, 32)            0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 19, 32)            128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 608)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               311808    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1, 256)            0         \n",
      "                                                                 \n",
      " gru (GRU)                   (None, 1, 256)            394752    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1, 128)            32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1, 64)             8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1, 32)             2080      \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 9)                 297       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 881673 (3.36 MB)\n",
      "Trainable params: 881609 (3.36 MB)\n",
      "Non-trainable params: 64 (256.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# model.add(keras.layers.Conv1D(filters=64, kernel_size=3, padding='same', activation='tanh', input_shape=inputShape))\n",
    "# model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "# # model.add(keras.layers.BatchNormalization())\n",
    "# model.add(keras.layers.Conv1D(filters=32, kernel_size=3, activation='sigmoid'))\n",
    "# model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "# model.add(keras.layers.BatchNormalization())\n",
    "# model.add(keras.layers.Flatten())\n",
    "# model.add(keras.layers.Dense(64, activation='relu'))\n",
    "# # model.add(keras.layers.Dropout(0.5))\n",
    "# model.add(keras.layers.Dense(32, activation='sigmoid'))\n",
    "# # model.add(keras.layers.Dropout(0.25))\n",
    "# model.add(keras.layers.Dense(16, activation='relu'))\n",
    "# model.add(keras.layers.Dense(num_classes, activation='tanh'))\n",
    "model.add(keras.layers.InputLayer(input_shape=inputShape))\n",
    "model.add(keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "# model.add(keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling1D(pool_size=2))\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "model.add(keras.layers.Flatten())\n",
    "# model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dense(256, activation='relu'))\n",
    "# model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Reshape((1, 256)))\n",
    "model.add(keras.layers.GRU(256, return_sequences=True, activation='relu'))\n",
    "model.add(keras.layers.Dense(128, activation='relu'))\n",
    "# model.add(keras.layers.GRU(128, return_sequences=True, activation='relu'))\n",
    "model.add(keras.layers.Dense(64, activation='sigmoid'))\n",
    "# model.add(keras.layers.LSTM(64, activation='relu', return_sequences=True))\n",
    "# model.add(keras.layers.Dropout(0.3))\n",
    "model.add(keras.layers.Dense(32, activation='relu'))\n",
    "model.add(keras.layers.Reshape((32,)))\n",
    "model.add(keras.layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "3754/3754 [==============================] - 45s 12ms/step - loss: 0.2719 - accuracy: 0.9066 - val_loss: 0.6645 - val_accuracy: 0.8102\n",
      "Epoch 2/15\n",
      "3754/3754 [==============================] - 45s 12ms/step - loss: 0.2717 - accuracy: 0.9070 - val_loss: 0.6641 - val_accuracy: 0.8108\n",
      "Epoch 3/15\n",
      "3754/3754 [==============================] - 46s 12ms/step - loss: 0.2662 - accuracy: 0.9080 - val_loss: 0.6727 - val_accuracy: 0.8091\n",
      "Epoch 4/15\n",
      "3754/3754 [==============================] - 46s 12ms/step - loss: 0.2685 - accuracy: 0.9084 - val_loss: 0.6624 - val_accuracy: 0.8127\n",
      "Epoch 5/15\n",
      "3754/3754 [==============================] - 47s 12ms/step - loss: 0.2612 - accuracy: 0.9098 - val_loss: 0.6774 - val_accuracy: 0.8048\n",
      "Epoch 6/15\n",
      "3754/3754 [==============================] - 48s 13ms/step - loss: 0.2651 - accuracy: 0.9092 - val_loss: 0.6617 - val_accuracy: 0.8117\n",
      "Epoch 7/15\n",
      "3754/3754 [==============================] - 49s 13ms/step - loss: 0.2598 - accuracy: 0.9111 - val_loss: 0.6889 - val_accuracy: 0.8091\n",
      "Epoch 8/15\n",
      "3754/3754 [==============================] - 49s 13ms/step - loss: 0.2595 - accuracy: 0.9114 - val_loss: 0.6728 - val_accuracy: 0.8118\n",
      "Epoch 9/15\n",
      "3754/3754 [==============================] - 50s 13ms/step - loss: 0.2609 - accuracy: 0.9108 - val_loss: 0.6960 - val_accuracy: 0.8031\n",
      "Epoch 10/15\n",
      "3754/3754 [==============================] - 52s 14ms/step - loss: 0.2579 - accuracy: 0.9118 - val_loss: 0.6663 - val_accuracy: 0.8107\n",
      "Epoch 11/15\n",
      "3754/3754 [==============================] - 52s 14ms/step - loss: 0.2586 - accuracy: 0.9113 - val_loss: 0.6894 - val_accuracy: 0.8101\n",
      "Epoch 12/15\n",
      "3754/3754 [==============================] - 54s 14ms/step - loss: 0.2589 - accuracy: 0.9116 - val_loss: 0.6659 - val_accuracy: 0.8127\n",
      "Epoch 13/15\n",
      "3754/3754 [==============================] - 55s 15ms/step - loss: 0.2580 - accuracy: 0.9116 - val_loss: 0.6606 - val_accuracy: 0.8116\n",
      "Epoch 14/15\n",
      "3754/3754 [==============================] - 55s 15ms/step - loss: 0.2606 - accuracy: 0.9112 - val_loss: 0.6818 - val_accuracy: 0.8090\n",
      "Epoch 15/15\n",
      "3754/3754 [==============================] - 55s 15ms/step - loss: 0.2610 - accuracy: 0.9107 - val_loss: 0.6758 - val_accuracy: 0.8076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x27389f72f50>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1609/1609 [==============================] - 4s 2ms/step - loss: 0.6687 - accuracy: 0.8090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6686773896217346, 0.808951199054718]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '3', '4', '5', '6', '7', '8']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[el.split('.')[0] for el in os.listdir(f'./saved_models/')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelVersion = 0\n",
    "if(os.path.exists('./saved_models/')):\n",
    "    modelVersion = max([0] if len([int(i) for i in [el.split('.')[0] for el in os.listdir(f'./saved_models/')]]) == 0 else [int(i) for i in [el.split('.')[0] for el in os.listdir(f'./saved_models/')]]) + 1\n",
    "else:\n",
    "    os.mkdir('./saved_models')\n",
    "\n",
    "model.save(f\"./saved_models/{modelVersion}.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 28ms/step\n",
      "1609/1609 [==============================] - 4s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_temp = model.predict(np.array([X_test[0]]))\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_mouthCues = [el.argmax() for el in predictions]\n",
    "predicted_mouthCues = [mouthCues[el] for el in predicted_mouthCues]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
